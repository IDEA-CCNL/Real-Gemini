import os
import shutil
import streamlit as st
from queue import Queue
import time
import cv2
from threading import Thread, Event

from .tools.tts_tool import TTSTool
from .utils_st.audio2text import audio2text_from_bytes
from .utils_st.extracte_img import get_main_img
from .utils_st.text2audio import autoplay_audio
from .utils_st.record_video import record

# è®¾ç½®äº‹ä»¶é”
event_record = Event()
event_chat = Event()
event_record.set() # åˆå§‹æ‰“å¼€å½•éŸ³é”

# å›¾ç‰‡ç¼“å­˜è·¯å¾„
IMAGE_BUFFER_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "img_buf")

# åˆå§‹åŒ–agent
from real_gemini.agent import ReActAgent
gemini_agent = ReActAgent()

with st.sidebar:
    with st.form('å‚æ•°é…ç½®'):
        max_chat_turn = st.slider('æœ€å¤§å¯¹è¯è½®æ•°:', min_value=1, max_value=10000, value=10)
        st.form_submit_button('æäº¤é…ç½®')
max_record_round = 2*max_chat_turn
q = Queue(max_record_round)

st.title("Gemini-likeå¯¹è¯æµ‹è¯•")
#########################å­˜å‚¨å½•å…¥çš„æ–‡ä»¶#####################
# RECORD_DIR = Path("./records")
# RECORD_DIR.mkdir(exist_ok=True)
# if "prefix" not in st.session_state:
#     st.session_state["prefix"] = str(uuid.uuid4())
# prefix = st.session_state["prefix"]
# in_file_video = RECORD_DIR / f"{prefix}_input_video.mp4"
# in_file_audio = RECORD_DIR / f"{prefix}_input_audio.mp3"
#########################å­˜å‚¨å½•å…¥çš„æ–‡ä»¶#####################
# å¯¹è¯æœºå™¨äººçš„å›¾æ ‡
img={'assistant':'./source/bot.png','user':None}

if "messages" not in st.session_state:
    st.session_state.messages = []

def my_recorder():
    for i in range(max_record_round):
        # ç­‰å¾…å½•å…¥æ¡ä»¶è§¦å‘ï¼Œæœ€å¼€å§‹æ˜¯é»˜è®¤è§¦å‘
        print('holding to record')
        event_record.wait()
        print(f'record {i}')
        imgs, audio = record()
        input_text,code_status,request_id = audio2text_from_bytes(audio.get_wav_data())
        if input_text and len(input_text)>5:
            q.put((imgs,audio,input_text))
        else:
            print(f'éé¢„æœŸè¾“å…¥: id--{request_id}, status--{code_status}, text--{input_text}')
            st.toast("æ— æ•ˆçš„è¯­éŸ³è¾“å…¥ï¼Œè¯·é‡è¯•ã€‚", icon="ğŸ¤–")
            time.sleep(2)# ç»™2ç§’æ—¶é—´ï¼Œè°ƒæ•´å‡†å¤‡è¾“å…¥
            continue
        print(f'{i}å½•åˆ¶ç»“æŸï¼Œ{q.qsize()}')
        # å½•åˆ¶ç»“æŸï¼Œè§£å¼€å¯¹è¯é˜»å¡ï¼ŒåŒæ—¶é˜»å¡ä¸‹ä¸€è½®å½•å…¥
        event_record.clear()
        event_chat.set()
        print('é‡Šæ”¾å¯¹è¯é”ï¼ŒåŠ å½•éŸ³é”')
    print('è¾“å…¥å¤„ç†æœåŠ¡ç»“æŸ')

def show_chat_message_from_history(show_num_history=None):
    # Display chat messages from history on app rerun
    # show_num_history: åº”å½“ä¸ºè´Ÿå¶æ•°æˆ–è€…æ­£å¥‡æ•°ï¼Œè´Ÿå¶æ•°è¡¨ç¤ºä¸ºæœ€åNæ¡ï¼Œæ­£æ•°è¡¨ç¤ºè·³è¿‡å‰Næ¡
    if show_num_history is None:
        history = st.session_state.messages
    else:
        history = st.session_state.messages[show_num_history:]
    for message in history:
        with st.chat_message(message["role"], avatar=img[message['role']]):
            if message['audio'] is not None:
                st.audio(message['audio'], sample_rate=24000)
            st.markdown(message["content"])
            if message['img'] is not None:
                st.image(message['img'])

def save_buf_image(imgs):
    if os.path.exists(IMAGE_BUFFER_DIR):
        shutil.rmtree(IMAGE_BUFFER_DIR)
    os.makedirs(IMAGE_BUFFER_DIR)
    for idx, img in enumerate(imgs):
        filename = os.path.join(IMAGE_BUFFER_DIR, f"image_{idx}.png")
        cv2.imwrite(filename, img)

def response(prompt=None, imgs=None, autoplay=True, audio_response=True):
    """
    promptï¼šè¾“å…¥çš„æ–‡æœ¬
    imgsï¼šè¾“å…¥çš„å›¾ç‰‡
    autoplayï¼šæ˜¯å¦è‡ªåŠ¨æ’­æ”¾è¯­éŸ³
    audio_responseï¼šæ˜¯å¦å°†æ–‡æœ¬è½¬æ¢æˆè¯­éŸ³å“åº”
    """
    if prompt:
        sound = None
        # Display user message in chat message container
        with st.chat_message("user"):
            st.markdown(prompt)
        # Add user message to chat history
            st.session_state.messages.append({"role": "user", "content": prompt})
        # Display assistant response in chat message container
        with st.chat_message("assistant", avatar='./source/bot.png'):
            # print("imgs:", imgs)
            save_buf_image(imgs)
            # res = gpt4v_client(query=prompt,imgs=imgs)
            res = gemini_agent.run(prompt=prompt, image_path_or_dir=IMAGE_BUFFER_DIR)
            print('res:', res)
            if audio_response:
                tts_tool = TTSTool()
                sound, rate, byte_sound_array = tts_tool.inference(res["text"])
            else:
                autoplay = False
            if autoplay:
                autoplay_audio(byte_sound_array)
            if not autoplay and audio_response:
                # ä¸è‡ªåŠ¨æ’­æ”¾è¯­éŸ³
                st.audio(sound, sample_rate=rate)
            st.markdown(res['text'])
            if res["text"] == "###":
                st.toast("æ— æ•ˆçš„è¯­éŸ³è¾“å…¥ï¼Œè¯·é‡è¯•ã€‚", icon="ğŸ¤–")
            # å¦‚æœæœ‰å›¾ç‰‡çš„è¯
            if "image" in res:
                st.image(res['image'])
            # ç”±äºæ˜¯è‡ªåŠ¨æ’­æ”¾éŸ³é¢‘ï¼Œéœ€è¦ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæ¯•
            if autoplay:
                time.sleep(int(len(sound)/rate)+1)
            # å¦‚æœæœ‰éŸ³é¢‘çš„è¯
            if "audio" in res:
                if autoplay:
                    autoplay_audio(res["audio"])
                    time.sleep(10)
                else:
                    st.audio(res['audio'])
            st.session_state.messages.append(
                {"role": "assistant", "content": res['text'], 'audio': sound})


def launch():
    max_round = max_chat_turn + 50 # ä¸ºäº†ä¿è¯å®‰å…¨ï¼Œæ²¡æœ‰å†™æ²¡æ¡ä»¶çš„whileå¾ªç¯
    record_thread = Thread(target=my_recorder)
    # å±•ç¤ºå½•åƒè®¾å¤‡çš„å›¾åƒä¿¡æ¯
    video_show = st.container()
    video_show.camera_input('tt', label_visibility='hidden')
    # å¼€å§‹å½•å…¥è¾“å…¥
    if video_show.button('å¼€å§‹å¯¹è¯'):
        record_thread.start()
    else:
        st.stop()
    # å±•ç¤ºå½•å…¥ä¿¡æ¯çš„å¤„ç†
    placeholder = st.empty()
    # å±•ç¤ºå¯¹è¯
    chat_placeholder = st.empty()
    while max_round > 0:
        # ç­‰å¾…å¯¹è¯å¼€å§‹ï¼Œåˆå§‹åŒ–æ˜¯é˜»å¡ï¼Œç­‰å¾…ç¬¬ä¸€æ¬¡è¾“å…¥å½•å…¥å®Œæˆï¼Œæ‰ä¼šæ‰“å¼€é”
        print('ç­‰å¾…å¯¹è¯å¼€å§‹')
        event_chat.wait()
        print('å¼€å§‹å¯¹è¯')
        if not q.empty():
            # è¿›å…¥åˆ°å¯¹è¯æ—¶ï¼Œåœæ­¢å½•å…¥ï¼Œé˜²æ­¢å½•å…¥æ’­æ”¾çš„éŸ³é¢‘
            print('è¿›å…¥å¯¹è¯å“åº”ï¼Œæš‚åœå½•å…¥')
            imgs,audio,input_text = q.get()
            with placeholder.status('å¤„ç†è¾“å…¥ä¿¡å·...', state='running', expanded=True) as status:
                if len(imgs) > 0:
                    st.write('è·å–å…³é”®å¸§...')
                    imgs = get_main_img(imgs, 3)
                    # imgs = imgs[-3:]
                    cls = st.columns(min(3, len(imgs)))
                    for idx, cl in enumerate(cls):
                        cl.image(cv2.cvtColor(imgs[idx], cv2.COLOR_BGR2RGB))
                st.audio(audio.get_wav_data())
                st.text(f'è¯†åˆ«åçš„æ–‡æœ¬ï¼š{input_text}')
                status.update(label="è¾“å…¥ä¿¡å·å¤„ç†å®Œæˆ", state="complete", expanded=False)
            with chat_placeholder.container():# 1.30æ”¯æŒè®¾ç½® height=300px
                # å®¹å™¨é«˜åº¦è®¾ç½®ï¼Œè¦ç­‰1.30ç‰ˆæœ¬æ›´æ–°ï¼Œhttps://github.com/streamlit/streamlit/issues/2169
                show_chat_message_from_history()
                response(prompt=input_text, imgs=imgs,autoplay=True, audio_response=True)
                print('å¯¹è¯å®Œæ¯•ï¼Œé‡Šæ”¾å½•éŸ³é”ï¼Œæ‰“å¼€å¯¹è¯é”')
                # å¯¹è¯å“åº”å®Œæ¯•ï¼Œæ‰“å¼€äº‹ä»¶
                event_record.set()
                # å¦‚æœæ²¡æœ‰å½•å…¥è¾“å…¥ï¼Œç­‰å¾…
                event_chat.clear()
            chat_placeholder.empty()
    print('è¾¾åˆ°æœ€å¤§å¯¹è¯è½®æ•°ï¼Œç»“æŸç¨‹åºï¼')
