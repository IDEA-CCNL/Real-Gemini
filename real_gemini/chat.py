import os
import sys
import shutil
import streamlit as st
from queue import Queue
import time
import cv2
from threading import Thread, Event
from .tools.tts_tool import TTSTool
from .utils.audio2text import audio2text_from_bytes
from .utils.image_selector import get_main_img
from .utils.text2audio import autoplay_audio
from .utils.record_video import record
from .agent import ReActAgent

class ChatEngine:
    # è®¾ç½®äº‹ä»¶é”
    event_record = Event()
    event_chat = Event()
    event_record.set() # åˆå§‹æ‰“å¼€å½•éŸ³é”
    record_round = 100
    # å›¾ç‰‡ç¼“å­˜è·¯å¾„
    image_buf_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "img_buf")

    # åˆå§‹åŒ–agent
    gemini_agent = ReActAgent()
    # äº‹ä»¶é˜Ÿåˆ—
    event_queue = Queue(record_round)
    # èµ„æº
    avatar_dict = {'assistant': './source/bot.png', 'user': None}

def record_handler():
    for round in range(ChatEngine.record_round):
        # ç­‰å¾…å½•å…¥æ¡ä»¶è§¦å‘ï¼Œæœ€å¼€å§‹æ˜¯é»˜è®¤è§¦å‘
        print('holding to record')
        ChatEngine.event_record.wait()
        print(f'record {round}')
        imgs, audio = record()
        input_text, code_status, request_id = audio2text_from_bytes(audio.get_wav_data())
        if input_text and len(input_text)>5:
            ChatEngine.event_queue.put((imgs, audio, input_text))
        else:
            ChatEngine.event_queue.put((imgs, audio, None))
            print(f'éé¢„æœŸè¾“å…¥: id--{request_id}, status--{code_status}, text--{input_text}')
        print(f'{round}å½•åˆ¶ç»“æŸï¼Œ{ChatEngine.event_queue.qsize()}')
        # å½•åˆ¶ç»“æŸï¼Œè§£å¼€å¯¹è¯é˜»å¡ï¼ŒåŒæ—¶é˜»å¡ä¸‹ä¸€è½®å½•å…¥
        ChatEngine.event_record.clear()
        ChatEngine.event_chat.set()
        print('é‡Šæ”¾å¯¹è¯é”ï¼ŒåŠ å½•éŸ³é”')
    print('è¾“å…¥å¤„ç†æœåŠ¡ç»“æŸ')

def show_chat_message_from_history(show_num_history=None):
    # Display chat messages from history on app rerun
    # show_num_history: åº”å½“ä¸ºè´Ÿå¶æ•°æˆ–è€…æ­£å¥‡æ•°ï¼Œè´Ÿå¶æ•°è¡¨ç¤ºä¸ºæœ€åNæ¡ï¼Œæ­£æ•°è¡¨ç¤ºè·³è¿‡å‰Næ¡
    if show_num_history is None:
        history = st.session_state.messages
    else:
        history = st.session_state.messages[show_num_history:]
    for message in history:
        with st.chat_message(message["role"], avatar=ChatEngine.avatar_dict[message['role']]):
            if 'audio' in message and message['audio'] is not None:
                st.audio(message['audio'], sample_rate=24000)
            st.markdown(message["content"])
            if 'img' in message and message['img'] is not None:
                st.image(message['img'])

def save_buf_image(imgs):
    if os.path.exists(ChatEngine.image_buf_dir):
        shutil.rmtree(ChatEngine.image_buf_dir)
    os.makedirs(ChatEngine.image_buf_dir)
    for idx, img in enumerate(imgs):
        filename = os.path.join(ChatEngine.image_buf_dir, f"image_{idx}.png")
        cv2.imwrite(filename, img)

def response(prompt=None, imgs=None, autoplay=True, audio_response=True):
    """
    promptï¼šè¾“å…¥çš„æ–‡æœ¬
    imgsï¼šè¾“å…¥çš„å›¾ç‰‡
    autoplayï¼šæ˜¯å¦è‡ªåŠ¨æ’­æ”¾è¯­éŸ³
    audio_responseï¼šæ˜¯å¦å°†æ–‡æœ¬è½¬æ¢æˆè¯­éŸ³å“åº”
    """
    if prompt:
        sound = None
        # Display user message in chat message container
        with st.chat_message("user"):
            st.markdown(prompt)
        # Add user message to chat history
            st.session_state.messages.append({"role": "user", "content": prompt})
        # Display assistant response in chat message container
        with st.chat_message("assistant", avatar='./source/bot.png'):
            save_buf_image(imgs)
            res = ChatEngine.gemini_agent.run(
                prompt=prompt, image_path_or_dir=ChatEngine.image_buf_dir)
            print('res:', res)
            # å¦‚æœæœ‰å›¾ç‰‡çš„è¯
            if "image" in res:
                st.image(res['image'])
            if res["text"] == "###":
                st.toast("æ— æ•ˆçš„è¯­éŸ³è¾“å…¥ï¼Œè¯·é‡è¯•ã€‚", icon="ğŸ¤–")
                st.markdown("æ— æ•ˆçš„è¯­éŸ³è¾“å…¥")
                res["text"] = "æ— æ•ˆçš„è¯­éŸ³è¾“å…¥"
            else:
                if audio_response:
                    tts_tool = TTSTool()
                    sound, rate, byte_sound_array = tts_tool.inference(res["text"])
                else:
                    autoplay = False
                if autoplay:
                    autoplay_audio(byte_sound_array)
                if not autoplay and audio_response:
                    # ä¸è‡ªåŠ¨æ’­æ”¾è¯­éŸ³
                    st.audio(sound, sample_rate=rate)
                st.markdown(res['text'])
                # ç”±äºæ˜¯è‡ªåŠ¨æ’­æ”¾éŸ³é¢‘ï¼Œéœ€è¦ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæ¯•
                if autoplay:
                    time.sleep(int(len(sound)/rate)+1)
            # å¦‚æœæœ‰éŸ³é¢‘çš„è¯
            if "audio" in res:
                if autoplay:
                    autoplay_audio(res["audio"])
                    time.sleep(10)
                else:
                    st.audio(res['audio'])
            st.session_state.messages.append(
                {"role": "assistant", "content": res['text'], 'audio': sound})


def launch():
    st.title("Real-Gemini")
    if "messages" not in st.session_state:
        st.session_state.messages = []
    # å±•ç¤ºå½•åƒè®¾å¤‡çš„å›¾åƒä¿¡æ¯
    video_show = st.container()
    video_show.camera_input('tt', label_visibility='hidden')
    # å¼€å§‹å½•å…¥è¾“å…¥
    record_thread = Thread(target=record_handler)
    if video_show.button('å¼€å§‹å¯¹è¯'):
        record_thread.start()
        st.balloons()
        st.info("ç°åœ¨ä½ å¯ä»¥å¼€å§‹è¿›è¡Œè¿ç»­çš„å¤šè½®å¯¹è¯äº†...")
    else:
        st.stop()
    # å±•ç¤ºå½•å…¥ä¿¡æ¯çš„å¤„ç†
    placeholder = st.empty()
    # å±•ç¤ºå¯¹è¯
    chat_placeholder = st.empty()
    while True:
        # ç­‰å¾…å¯¹è¯å¼€å§‹ï¼Œåˆå§‹åŒ–æ˜¯é˜»å¡ï¼Œç­‰å¾…ç¬¬ä¸€æ¬¡è¾“å…¥å½•å…¥å®Œæˆï¼Œæ‰ä¼šæ‰“å¼€é”
        print('ç­‰å¾…å¯¹è¯å¼€å§‹')
        ChatEngine.event_chat.wait()
        print('å¼€å§‹å¯¹è¯')
        if not ChatEngine.event_queue.empty():
            # è¿›å…¥åˆ°å¯¹è¯æ—¶ï¼Œåœæ­¢å½•å…¥ï¼Œé˜²æ­¢å½•å…¥æ’­æ”¾çš„éŸ³é¢‘
            print('è¿›å…¥å¯¹è¯å“åº”ï¼Œæš‚åœå½•å…¥')
            imgs, audio, input_text = ChatEngine.event_queue.get()
            if input_text:
                with placeholder.status('å¤„ç†è¾“å…¥ä¿¡å·...', state='running', expanded=True) as status:
                    if len(imgs) > 0:
                        st.write('è·å–å…³é”®å¸§...')
                        imgs = get_main_img(imgs, 3)
                        cls = st.columns(min(3, len(imgs)))
                        for idx, cl in enumerate(cls):
                            cl.image(cv2.cvtColor(imgs[idx], cv2.COLOR_BGR2RGB))
                    st.audio(audio.get_wav_data())
                    st.text(f'è¯†åˆ«åçš„æ–‡æœ¬ï¼š{input_text}')
                    status.update(label="è¾“å…¥ä¿¡å·å¤„ç†å®Œæˆ", state="complete", expanded=False)
                with st.spinner('ç©å‘½è·‘agentä¸­...'):
                    with chat_placeholder.container():# 1.30æ”¯æŒè®¾ç½® height=300px
                        # å®¹å™¨é«˜åº¦è®¾ç½®ï¼Œè¦ç­‰1.30ç‰ˆæœ¬æ›´æ–°ï¼Œhttps://github.com/streamlit/streamlit/issues/2169
                        show_chat_message_from_history()
                        response(
                            prompt=input_text,
                            imgs=imgs,
                            autoplay=True,
                            audio_response=True
                        )
            else:
                st.toast("æ— æ•ˆçš„è¯­éŸ³è¾“å…¥ï¼Œè¯·é‡è¯•ã€‚", icon="ğŸ¤–")
                time.sleep(2)# ç»™2ç§’æ—¶é—´ï¼Œè°ƒæ•´å‡†å¤‡è¾“å…¥
            print('å¯¹è¯å®Œæ¯•ï¼Œé‡Šæ”¾å½•éŸ³é”ï¼Œæ‰“å¼€å¯¹è¯é”')
            # å¯¹è¯å“åº”å®Œæ¯•ï¼Œæ‰“å¼€äº‹ä»¶
            ChatEngine.event_record.set()
            # å¦‚æœæ²¡æœ‰å½•å…¥è¾“å…¥ï¼Œç­‰å¾…
            ChatEngine.event_chat.clear()
            chat_placeholder.empty()

